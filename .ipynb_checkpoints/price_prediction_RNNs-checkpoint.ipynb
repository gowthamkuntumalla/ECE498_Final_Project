{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"author: GK\"\"\"\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "from os import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import data \"\"\"\n",
    "\n",
    "all_features_df = pd.read_csv('All_features_df.csv')\n",
    "tickers = all_features_df.Name.unique()\n",
    "all_features_df['date'] = pd.to_datetime(all_features_df['date'],format='%Y-%m-%d')\n",
    "all_features_df.set_index(['Name','date'],inplace = True) # custom created features\n",
    "orig_features_df = all_features_df.loc[:,['open','high','low','close','volume']] # O,H,L,C,Volume only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Target industries \"\"\"\n",
    "weblink = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "industries_df = pd.read_html(weblink)[0]\n",
    "industries_df.to_csv('wiki_sp500_industries.csv')\n",
    "print(industries_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for prediction\"\"\"\n",
    "orig_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: use about 80% of past years' data to predict 20% of future years' data. <br>  <br>\n",
    "Split roughly<br>\n",
    "Train: 4 years (Feb 2013 to Feb 2017)<br>\n",
    "Test: 1 year (Feb 2017 to Feb 2018)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative approaches: \n",
    "1. XGboost with technical indicators (https://medium.com/@hsahu/stock-prediction-with-xgboost-a-technical-indicators-approach-5f7e5940e9e3)\n",
    "2. Multinomial regression\n",
    "3. ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_features_df.loc['AAPL'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/rnn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,callbacks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trial for AAPL data\n",
    "dataset = orig_features_df.loc['AAPL'].to_numpy()\n",
    "n_features = np.shape(dataset)[1]\n",
    "# normalize the dataset - LSTMS are scale dependent\n",
    "scaler = MinMaxScaler(feature_range=(0, 1),copy = True)\n",
    "dataset = scaler.fit_transform(dataset.reshape(-1,n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookback for LSTM\n",
    "lstm_period = 32\n",
    "\n",
    "def look_back(data,period = 7):\n",
    "    X,y = [],[]\n",
    "    for i in range(period,len(data)):\n",
    "        X.append(data[i-period:i,:])\n",
    "        y.append(data[i,:])\n",
    "    return np.array(X),np.array(y)\n",
    "X,y = look_back(dataset,lstm_period)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split: 80 : 20\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X)*train_ratio)\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = X[0:train_size,:], X[train_size:,:]\n",
    "y_train, y_test = y[0:train_size], y[train_size:]\n",
    "print(len(X_train), len(X_test),len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTMModel(n1_cells = 128, n2_cells = 16,dropout_rate=0, optimizer='Adam',\\\n",
    "                    activation='tanh', loss='mean_squared_error', \n",
    "                    epochs = 100,batch_size = 16):\n",
    "    \n",
    "    # simple model: Build-Compile-Fit-Predict approach\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(n1_cells,activation=activation,return_sequences = True,use_bias=True,\\\n",
    "                               input_shape = (lstm_period,n_features))) #recurrent_activation = 'sigmoid'\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.LSTM(n2_cells,activation=activation,use_bias=True))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(n_features))\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "    # Reshape Data: (Sample,Timestep,Features) \n",
    "    model.fit(X_train,y_train,shuffle = False,epochs = epochs,verbose = 1,batch_size = batch_size,\\\n",
    "                   callbacks=[callbacks.EarlyStopping(monitor='loss', patience=3)])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search CV\n",
    "\n",
    "grid_param_LSTM = {\n",
    "    'n1_cells' : [16],\n",
    "    'n2_cells' : [4],\n",
    "    'batch_size': [1],\n",
    "    'epochs': [100],   \n",
    "    'optimizer': ['Adam', 'RMSProp'],\n",
    "#     'loss': ['logcosh', 'mse'],\n",
    "#     'activation': ['relu', 'linear','sigmoid', 'tanh'],\n",
    "#     'dropout_rate':[0,0.5]\n",
    "}\n",
    "\n",
    "model_LSTM=KerasRegressor(build_fn=createLSTMModel)\n",
    "\n",
    "\n",
    "GridLSTM = GridSearchCV(estimator=model_LSTM,\n",
    "                     param_grid=grid_param_LSTM,\n",
    "                     scoring={'neg_mean_squared_error'},\n",
    "                     refit = 'neg_mean_squared_error', cv=3,n_jobs = -1)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],n_features))\n",
    "\n",
    "GridLSTM.fit(X_train, y_train)\n",
    "best_model = GridLSTM.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mkdir('Results')\n",
    "except:\n",
    "    pass\n",
    "best_model.save('Results/lstm_model.h5')\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "GridLSTM.save('Results/grid_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_seen = best_model.predict(X_train)\n",
    "# y_pred_unseen = best_model.predict(X_test) # This is not completely correct as it is peeking into the future\n",
    "print(np.shape(y_pred_seen))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "plt.plot(scaler.inverse_transform(y_pred_seen)[:,0],color = 'b',label = 'Predicted_SEEN')\n",
    "plt.plot(scaler.inverse_transform(y_train)[:,0],color = 'k',label = 'Actual_SEEN_data')\n",
    "plt.xlabel('#(day)')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Prediction in SEEN AAPL data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"Note the commented block here is peeking into the future data while prediciting \"\"\"\n",
    "# pred_unseen_to_plot = len(y_train)\n",
    "# plt.figure(figsize = (16,10))\n",
    "# plt.plot(scaler.inverse_transform(y_pred_unseen)[:,0],color = 'r',label = 'Predicted_UNSEEN')\n",
    "# plt.plot(scaler.inverse_transform(y_test)[:,0],color = 'k',label = 'Actual_UNSEEN_data')\n",
    "# plt.xlabel('#(day)')\n",
    "# plt.ylabel('Price')\n",
    "# plt.title('Prediction in UNSEEN AAPL data')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for 365 days\n",
    "# start = X_train[-1:]\n",
    "start = X_test[0:1]\n",
    "preds = [[np.nan]*n_features]\n",
    "for i in range(250):\n",
    "    start = start.reshape((start.shape[0],start.shape[1],n_features))\n",
    "    a = best_model.predict(start)\n",
    "    # prepare next start point\n",
    "    first_n_minus_1 = start[0,-(lstm_period-1):,0:n_features]\n",
    "    first_n_minus_1 = first_n_minus_1.reshape((1,first_n_minus_1.shape[0],n_features))\n",
    "    a = a.reshape((1,a.shape[0],n_features))\n",
    "    start = np.concatenate((first_n_minus_1,a), axis = 1)   \n",
    "    preds = np.concatenate((preds,a[0]),axis = 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unseen_to_plot = len(y_train)\n",
    "plt.figure(figsize = (16,10))\n",
    "plt.plot(scaler.inverse_transform(preds)[:,0],color = 'r',label = 'Predicted_UNSEEN')\n",
    "plt.plot(scaler.inverse_transform(y_test)[:,0],color = 'k',label = 'Actual_UNSEEN_data')\n",
    "plt.xlabel('#(day)')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Prediction in UNSEEN AAPL data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
